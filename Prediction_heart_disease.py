import pandas as pd
import seaborn as sns
import joblib
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc
import os
# Chargement des donn√©es
df = pd.read_csv('framingham.csv')
df.info()
df.head()
df.describe()
# Gestion des valeurs manquantes
df.fillna(df.median(), inplace=True)
#Suppression des colonnes vides:
df = df.loc[:, ~df.isna().all()]
# Suppression des doublons
df.drop_duplicates(inplace=True)
#La visualisation et la gestion des valeurs aberrantes
numeric_cols = [col for col in df.select_dtypes(include=["number"]).columns if col != 'TenYearCHD']
plt.figure(figsize=(15, 10))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(4, 4, i)
    sns.boxplot(y=df[col])
    plt.title(col)
plt.tight_layout()
plt.show()
def remove_outliers(df, numeric_cols):
    Q1 = df[numeric_cols].quantile(0.25)
    Q3 = df[numeric_cols].quantile(0.75)
    IQR = Q3 - Q1
    mask = ~((df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)
    return df[mask]
df = remove_outliers(df, numeric_cols)
#Suppression des colonnes √† variance nulle
df = df.loc[:, df.var() != 0]

# S√©paration des features et de la cible
X = df.drop("TenYearCHD", axis=1)
y = df["TenYearCHD"]

# Gestion du d√©s√©quilibre avec SMOTE
smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(X, y)

# La matrice de corr√©lation
matrice_correlation = df.corr()
print("Matrice de Corr√©lation :")
print(matrice_correlation)
# Visualisation de la matrice de corr√©lation
plt.figure(figsize=(12, 8))
sns.heatmap(matrice_correlation, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)
plt.title('Matrice de Corr√©lation')
plt.show()
#Tester la multicolin√©arit√©
X_const = add_constant(X)
vif_data = pd.DataFrame()
vif_data["Variable"] = X_const.columns
vif_data["VIF"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]
print(vif_data)
plt.figure(figsize=(8, 6))
sns.barplot(x='VIF', y='Variable', data=vif_data.sort_values('VIF', ascending=False), palette='viridis')
plt.title("Variance Inflation Factor (VIF) pour chaque variable")
plt.xlabel("VIF")
plt.ylabel("Variable")
plt.show()
# Division en ensembles d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Normalisation des donn√©es
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# D√©finition des mod√®les
models = {
    "Logistic Regression": LogisticRegression(solver='liblinear', C=1),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss"),
    "SVM": SVC(kernel="linear", probability=True),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "Naive Bayes": GaussianNB()
}

## Entra√Ænement et √©valuation des mod√®les
def evaluate_models(models, X_train, y_train, X_test, y_test):
    results = []
    fpr_dict, tpr_dict, auc_dict = {}, {}, {}

    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None
        
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_prob) if y_pred_prob is not None else 0

        fpr, tpr, _ = roc_curve(y_test, y_pred_prob) if y_pred_prob is not None else (None, None, None)

        fpr_dict[name], tpr_dict[name] = fpr, tpr
        auc_dict[name] = auc

        results.append({
            "Mod√®le": name, "Accuracy": accuracy, "Precision": precision,
            "Recall": recall, "F1 Score": f1, "AUC": auc
        })
        # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["N√©gatif", "Positif"], yticklabels=["N√©gatif", "Positif"])
        plt.xlabel("Pr√©dit")
        plt.ylabel("R√©el")
        plt.title(f"Matrice de confusion - {name}")
        plt.show()

    return pd.DataFrame(results), fpr_dict, tpr_dict, auc_dict

# Ex√©cution de l'√©valuation
results_df, fpr_dict, tpr_dict, auc_dict = evaluate_models(models, X_train_scaled, y_train, X_test_scaled, y_test)

# S√©lection du meilleur mod√®le
best_model_row = results_df.sort_values(by="AUC", ascending=False).iloc[0]
best_model_name = best_model_row["Mod√®le"]
best_model = models[best_model_name]

# Sauvegarde du meilleur mod√®le
joblib.dump(best_model, "best_model.pkl")
# Sauvegarder le scaler
joblib.dump(scaler, "scaler.pkl")
print(f"üèÜ Meilleur mod√®le : {best_model_name} sauvegard√© sous 'best_model.pkl'.")

# Visualisation des scores AUC
plt.figure(figsize=(10, 5))
sns.barplot(x="Mod√®le", y="AUC", data=results_df.sort_values(by="AUC", ascending=False), palette="Blues_r")
plt.xticks(rotation=45)
plt.title("Comparaison des mod√®les selon l'AUC")
plt.show()

# Visualisation des courbes ROC pour tous les mod√®les
plt.figure(figsize=(10, 8))
for name in models.keys():
    if fpr_dict[name] is not None and tpr_dict[name] is not None:
        plt.plot(fpr_dict[name], tpr_dict[name], label=f'{name} (AUC = {auc_dict[name]:.2f})')

plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonale al√©atoire
plt.title("Courbes ROC pour tous les mod√®les")
plt.xlabel("Taux de Faux Positifs (FPR)")
plt.ylabel("Taux de Vrais Positifs (TPR)")
plt.legend(loc="lower right")
plt.show()

# Courbe ROC pour le meilleur mod√®le
y_pred_prob_best = best_model.predict_proba(X_test_scaled)[:, 1]
fpr_best, tpr_best, _ = roc_curve(y_test, y_pred_prob_best)
roc_auc_best = auc(fpr_best, tpr_best)

plt.figure(figsize=(10, 8))
plt.plot(fpr_best, tpr_best, label=f'{best_model_name} (AUC = {roc_auc_best:.2f})', color='red')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonale al√©atoire
plt.title(f"Courbe ROC pour le meilleur mod√®le : {best_model_name}")
plt.xlabel("Taux de Faux Positifs (FPR)")
plt.ylabel("Taux de Vrais Positifs (TPR)")
plt.legend(loc="lower right")
plt.show()
# Matrice de confusion pour le meilleur mod√®le
y_pred_best = best_model.predict(X_test_scaled)
cm_best = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_best, annot=True, fmt="d", cmap="Blues", xticklabels=["N√©gatif", "Positif"], yticklabels=["N√©gatif", "Positif"])
plt.xlabel("Pr√©dit")
plt.ylabel("R√©el")
plt.title(f"Matrice de confusion - {best_model_name}")
plt.show()
### deploiement du projet  sur Streamlit ###

# Charger le mod√®le et le scaler
# Informations sur l'application (sidebar avec Markdown)
st.sidebar.title('Pr√©diction des Maladies Cardiaques ü´Ä')

# Affichage des emojis dans la barre lat√©rale
st.image("Images/Image1.jpg", caption="Prediction Heart disease",use_container_width =True)
#st.image("Images/Image2.jpg", caption="Illustration Repr√©sentative", use_container_width=True)
st.sidebar.markdown("""
Bienvenue dans notre application d√©di√©e √† la **pr√©diction du risque de maladies cardiaques** ! ü´Äüíì

### üö® **D√©finition des maladies cardiaques**
Les maladies cardiaques d√©signent un ensemble de troubles affectant le c≈ìur et les vaisseaux sanguins, notamment :
- **Infarctus du myocarde** üíî
- **Angine de poitrine** üí•
- **Insuffisance cardiaque** ü´£

### üåü **Causes des maladies cardiaques** üåü
Elles peuvent √™tre caus√©es par divers facteurs, tels que :
- **Hypertension art√©rielle** ‚¨ÜÔ∏è : Augmente la charge de travail du c≈ìur.
- **Hypercholest√©rol√©mie** üß¥ : Accumulation de plaques dans les art√®res.
- **Tabagisme** üö¨ : Endommage les vaisseaux sanguins et r√©duit l'apport en oxyg√®ne.
- **Ob√©sit√© et s√©dentarit√©** ‚öñÔ∏è : Risques li√©s √† un mode de vie inactif.
- **Diab√®te** üç© : Risque accru de complications cardiaques.

### üßê **Objectif de l'√©tude**
L'objectif est de construire un mod√®le qui pr√©dit le risque de maladies cardiaques bas√© sur les caract√©ristiques m√©dicales et de mode de vie. Cela peut aider les professionnels de sant√© √† d√©tecter les risques chez les patients et √† prendre des mesures pr√©ventives.

### üîß **Mod√®les utilis√©s** :
Nous avons utilis√© plusieurs mod√®les de Machine Learning pour cette t√¢che :
1. **R√©gression Logistique** üîÑ : Pour des pr√©dictions simples mais efficaces.
2. **Random Forest** üå≤üå≤ : Pour des performances robustes avec des arbres de d√©cision multiples.
3. **XGBoost** üöÄ : Un mod√®le puissant bas√© sur le boosting d'arbres de d√©cision.
4. **SVM (Support Vector Machine)** üßë‚Äçüíª : Pour les probl√®mes de classification avec des fronti√®res de d√©cision.
5. **KNN (K-Nearest Neighbors)** üëØ‚Äç‚ôÇÔ∏è : Bas√© sur les voisins les plus proches pour classifier les patients.
6. **Naive Bayes** üìä : Un mod√®le probabiliste simple mais efficace.

Tous ces mod√®les ont √©t√© √©valu√©s avec des crit√®res comme la **pr√©cision** (accuracy), le **rappel** (recall), la **pr√©cision** (precision), le **score F1**, et l'**AUC** (Area Under the Curve).

### ‚ö†Ô∏è **Attention :** 
Les r√©sultats de la pr√©diction sont une estimation bas√©e sur des donn√©es m√©dicales. Il est important de consulter un professionnel de sant√© pour un diagnostic exact. ü©∫

""")
def user_input_features():
    st.title('Pr√©diction du Risque de Maladies Cardiaques üíñ')
 # Dictionary to map education levels to numerical values
    education_map = {
        "√âl√©mentaire": 1,
        "Secondaire": 2,
        "Coll√®ge": 3,
        "Lyc√©e": 4,
        "Universit√©": 5,
        "Post-universitaire": 6,
        "Doctorat": 7
    }
    features = {
        'male': st.selectbox('Sexe biologique (Masculin, F√©minin)', ['F√©minin', 'Masculin']),
        'age': st.number_input('√Çge du patient en ann√©es üßë‚Äçü¶≥', 20, 100, 50),
        'education': st.selectbox(
            "Niveau d'√©ducation atteint",
            list(education_map.keys())
        ),
        'currentSmoker': st.selectbox('Le patient est-il fumeur ? (Non, Oui) üö¨', ['Non', 'Oui']),
    }

    # Ajouter la logique conditionnelle pour le nombre de cigarettes fum√©es
    if 'currentSmoker' in features:  # V√©rifier que la cl√© 'currentSmoker' est pr√©sente
        if features['currentSmoker'] == 'Oui':
            features['cigsPerDay'] = st.number_input('Nombre de cigarettes fum√©es par jour üö¨', 0, 100, 0)
        else:
            features['cigsPerDay'] = 0

    additional_features = {
        'prevalentHyp': st.selectbox("Pr√©sence d'hypertension art√©rielle ? (Non, Oui) üíî", ['Non', 'Oui']),
        'totChol': st.number_input('Taux de cholest√©rol total en mg/dL üß™', 100, 600, 200),
        'sysBP': st.number_input('Pression art√©rielle systolique (mmHg) üíâ', 80, 200, 120),
        'diaBP': st.number_input('Pression art√©rielle diastolique (mmHg) üíâ', 40, 150, 80),
        'BMI': st.number_input('Indice de Masse Corporelle (IMC) ‚öñÔ∏è', 10.0, 60.0, 25.0),
        'heartRate': st.number_input('Fr√©quence cardiaque (battements par minute) ‚ù§Ô∏è', 40, 200, 70),
        'glucose': st.number_input('Taux de glucose sanguin en mg/dL ü©∏', 40, 300, 100)
    }

    features.update(additional_features)

    # Convertir les colonnes cat√©gorielles en num√©riques
    features['male'] = 1 if features['male'] == 'Masculin' else 0
    features['currentSmoker'] = 1 if features['currentSmoker'] == 'Oui' else 0
    features['prevalentHyp'] = 1 if features['prevalentHyp'] == 'Oui' else 0
    features['education'] = education_map[features['education']]    
    return pd.DataFrame([features])

user_input = user_input_features()


if st.button('Faire la pr√©diction üß†'):
    
    model = joblib.load('best_model.pkl')
    scaler = joblib.load('scaler.pkl')

    input_data_scaled = scaler.transform(user_input)
    prediction = model.predict(input_data_scaled)
    prediction_prob = model.predict_proba(input_data_scaled)[:, 1]  # Probabilit√© de la classe positive

    if prediction[0] == 0:
        st.success("Le patient n'a pas de risque √©lev√© de maladie cardiaque. ‚úÖ")
    else:
        st.warning("Le patient pr√©sente un risque √©lev√© de maladie cardiaque. ‚ö†Ô∏è")

    st.write(f"Probabilit√© de risque √©lev√© : {prediction_prob[0]:.4f}")


