import pandas as pd
import seaborn as sns
import joblib
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc

# Chargement des donn√©es
df = pd.read_csv('framingham.csv')
df.info()
df.head()
df.describe()
# Gestion des valeurs manquantes
df.fillna(df.median(), inplace=True)
#Suppression des colonnes vides:
df = df.loc[:, ~df.isna().all()]
# Suppression des doublons
df.drop_duplicates(inplace=True)
#La visualisation et la gestion des valeurs aberrantes
numeric_cols = [col for col in df.select_dtypes(include=["number"]).columns if col != 'TenYearCHD']
plt.figure(figsize=(15, 10))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(4, 4, i)
    sns.boxplot(y=df[col])
    plt.title(col)
plt.tight_layout()
plt.show()
def remove_outliers(df, numeric_cols):
    Q1 = df[numeric_cols].quantile(0.25)
    Q3 = df[numeric_cols].quantile(0.75)
    IQR = Q3 - Q1
    mask = ~((df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)
    return df[mask]
df = remove_outliers(df, numeric_cols)
#Suppression des colonnes √† variance nulle
df = df.loc[:, df.var() != 0]

# S√©paration des features et de la cible
X = df.drop("TenYearCHD", axis=1)
y = df["TenYearCHD"]

# Gestion du d√©s√©quilibre avec SMOTE
smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(X, y)

# La matrice de corr√©lation
matrice_correlation = df.corr()
print("Matrice de Corr√©lation :")
print(matrice_correlation)
# Visualisation de la matrice de corr√©lation
plt.figure(figsize=(12, 8))
sns.heatmap(matrice_correlation, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)
plt.title('Matrice de Corr√©lation')
plt.show()
#Tester la multicolin√©arit√©
X_const = add_constant(X)
vif_data = pd.DataFrame()
vif_data["Variable"] = X_const.columns
vif_data["VIF"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]
print(vif_data)
plt.figure(figsize=(8, 6))
sns.barplot(x='VIF', y='Variable', data=vif_data.sort_values('VIF', ascending=False), palette='viridis')
plt.title("Variance Inflation Factor (VIF) pour chaque variable")
plt.xlabel("VIF")
plt.ylabel("Variable")
plt.show()
# Division en ensembles d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Normalisation des donn√©es
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# D√©finition des mod√®les
models = {
    "Logistic Regression": LogisticRegression(solver='liblinear', C=1),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss"),
    "SVM": SVC(kernel="linear", probability=True),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "Naive Bayes": GaussianNB()
}

## Entra√Ænement et √©valuation des mod√®les
def evaluate_models(models, X_train, y_train, X_test, y_test):
    results = []
    fpr_dict, tpr_dict, auc_dict = {}, {}, {}

    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_pred_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None
        
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_prob) if y_pred_prob is not None else 0

        fpr, tpr, _ = roc_curve(y_test, y_pred_prob) if y_pred_prob is not None else (None, None, None)

        fpr_dict[name], tpr_dict[name] = fpr, tpr
        auc_dict[name] = auc

        results.append({
            "Mod√®le": name, "Accuracy": accuracy, "Precision": precision,
            "Recall": recall, "F1 Score": f1, "AUC": auc
        })
        # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["N√©gatif", "Positif"], yticklabels=["N√©gatif", "Positif"])
        plt.xlabel("Pr√©dit")
        plt.ylabel("R√©el")
        plt.title(f"Matrice de confusion - {name}")
        plt.show()

    return pd.DataFrame(results), fpr_dict, tpr_dict, auc_dict

# Ex√©cution de l'√©valuation
results_df, fpr_dict, tpr_dict, auc_dict = evaluate_models(models, X_train_scaled, y_train, X_test_scaled, y_test)

# S√©lection du meilleur mod√®le
best_model_row = results_df.sort_values(by="AUC", ascending=False).iloc[0]
best_model_name = best_model_row["Mod√®le"]
best_model = models[best_model_name]

# Sauvegarde du meilleur mod√®le
joblib.dump(best_model, "best_model.pkl")
# Sauvegarder le scaler
joblib.dump(scaler, "scaler.pkl")
print(f"üèÜ Meilleur mod√®le : {best_model_name} sauvegard√© sous 'best_model.pkl'.")

# Visualisation des scores AUC
plt.figure(figsize=(10, 5))
sns.barplot(x="Mod√®le", y="AUC", data=results_df.sort_values(by="AUC", ascending=False), palette="Blues_r")
plt.xticks(rotation=45)
plt.title("Comparaison des mod√®les selon l'AUC")
plt.show()

# Visualisation des courbes ROC pour tous les mod√®les
plt.figure(figsize=(10, 8))
for name in models.keys():
    if fpr_dict[name] is not None and tpr_dict[name] is not None:
        plt.plot(fpr_dict[name], tpr_dict[name], label=f'{name} (AUC = {auc_dict[name]:.2f})')

plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonale al√©atoire
plt.title("Courbes ROC pour tous les mod√®les")
plt.xlabel("Taux de Faux Positifs (FPR)")
plt.ylabel("Taux de Vrais Positifs (TPR)")
plt.legend(loc="lower right")
plt.show()

# Courbe ROC pour le meilleur mod√®le
y_pred_prob_best = best_model.predict_proba(X_test_scaled)[:, 1]
fpr_best, tpr_best, _ = roc_curve(y_test, y_pred_prob_best)
roc_auc_best = auc(fpr_best, tpr_best)

plt.figure(figsize=(10, 8))
plt.plot(fpr_best, tpr_best, label=f'{best_model_name} (AUC = {roc_auc_best:.2f})', color='red')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonale al√©atoire
plt.title(f"Courbe ROC pour le meilleur mod√®le : {best_model_name}")
plt.xlabel("Taux de Faux Positifs (FPR)")
plt.ylabel("Taux de Vrais Positifs (TPR)")
plt.legend(loc="lower right")
plt.show()
# Matrice de confusion pour le meilleur mod√®le
y_pred_best = best_model.predict(X_test_scaled)
cm_best = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_best, annot=True, fmt="d", cmap="Blues", xticklabels=["N√©gatif", "Positif"], yticklabels=["N√©gatif", "Positif"])
plt.xlabel("Pr√©dit")
plt.ylabel("R√©el")
plt.title(f"Matrice de confusion - {best_model_name}")
plt.show()
### deploiement du projet  sur Streamlit ###

# Charger le mod√®le et le scaler
# Informations sur l'application (sidebar avec Markdown)
st.sidebar.title('Pr√©diction des Maladies Cardiaques üíñ')
st.sidebar.markdown("""
Cette application utilise des mod√®les de Machine Learning pour pr√©dire le risque de maladies cardiaques sur la base de plusieurs caract√©ristiques m√©dicales.

### D√©finition des maladies cardiaques
Les maladies cardiaques d√©signent un ensemble de troubles affectant le c≈ìur et les vaisseaux sanguins, notamment l'infarctus du myocarde, l'angine de poitrine et l'insuffisance cardiaque.

### Causes des maladies cardiaques
Elles peuvent √™tre caus√©es par divers facteurs, tels que :
- **Hypertension art√©rielle** : Augmente la charge de travail du c≈ìur.
- **Hypercholest√©rol√©mie** : Provoque l'accumulation de plaques dans les art√®res.
- **Tabagisme** : Endommage les vaisseaux sanguins et r√©duit l'apport d'oxyg√®ne au c≈ìur.
- **Ob√©sit√© et s√©dentarit√©** : Favorisent le d√©veloppement des maladies cardiovasculaires.
- **Diab√®te** : Augmente le risque de complications cardiaques.

### Objectif de l'√©tude
L'objectif est de construire un mod√®le capable de pr√©dire le risque de maladies cardiaques en utilisant diverses caract√©ristiques m√©dicales et de style de vie. Cette √©tude peut aider les professionnels de sant√© √† identifier les patients √† risque et √† mettre en place des mesures pr√©ventives adapt√©es.

### Mod√®les utilis√©s :
1. **R√©gression Logistique** : Un mod√®le simple et efficace pour les probl√®mes de classification binaire.
2. **Random Forest** : Un ensemble d'arbres de d√©cision qui offre une bonne performance en capturant des relations complexes.
3. **XGBoost** : Un mod√®le bas√© sur des arbres de d√©cision avec des capacit√©s d'apprentissage boost√©.
4. **SVM (Support Vector Machine)** : Utilise des fronti√®res de d√©cision pour classer les donn√©es.
5. **KNN (K-Nearest Neighbors)** : Classifie en fonction des voisins les plus proches.
6. **Naive Bayes** : Bas√© sur des probabilit√©s conditionnelles.

Ces mod√®les ont √©t√© √©valu√©s sur leur pr√©cision (accuracy), leur rappel (recall), leur pr√©cision (precision), leur score F1 et leur AUC (Area Under the Curve).
""")
def user_input_features():
    st.title('Pr√©diction du Risque de Maladies Cardiaques üíñ')

    features = {
        'male': st.selectbox('Sexe biologique (Masculin, F√©minin)', ['F√©minin', 'Masculin']),
        'age': st.number_input('√Çge du patient en ann√©es üßë‚Äçü¶≥', 20, 100, 50),
        'education': st.selectbox(
            "Niveau d'√©ducation atteint",
            ["√âl√©mentaire", "Secondaire", "Coll√®ge", "Lyc√©e", "Universit√©", "Post-universitaire", "Doctorat"]
        ),
        'currentSmoker': st.selectbox('Le patient est-il fumeur ? (Non, Oui) üö¨', ['Non', 'Oui']),
    }

    # Ajouter la logique conditionnelle pour le nombre de cigarettes fum√©es
    if 'currentSmoker' in features:  # V√©rifier que la cl√© 'currentSmoker' est pr√©sente
        if features['currentSmoker'] == 'Oui':
            features['cigsPerDay'] = st.number_input('Nombre de cigarettes fum√©es par jour üö¨', 0, 100, 0)
        else:
            features['cigsPerDay'] = 0

    additional_features = {
        'prevalentHyp': st.selectbox("Pr√©sence d'hypertension art√©rielle ? (Non, Oui) üíî", ['Non', 'Oui']),
        'totChol': st.number_input('Taux de cholest√©rol total en mg/dL üß™', 100, 600, 200),
        'sysBP': st.number_input('Pression art√©rielle systolique (mmHg) üíâ', 80, 200, 120),
        'diaBP': st.number_input('Pression art√©rielle diastolique (mmHg) üíâ', 40, 150, 80),
        'BMI': st.number_input('Indice de Masse Corporelle (IMC) ‚öñÔ∏è', 10.0, 60.0, 25.0),
        'heartRate': st.number_input('Fr√©quence cardiaque (battements par minute) ‚ù§Ô∏è', 40, 200, 70),
        'glucose': st.number_input('Taux de glucose sanguin en mg/dL ü©∏', 40, 300, 100)
    }

    features.update(additional_features)

    # Convertir les colonnes cat√©gorielles en num√©riques
    features['male'] = 1 if features['male'] == 'Masculin' else 0
    features['currentSmoker'] = 1 if features['currentSmoker'] == 'Oui' else 0
    features['prevalentHyp'] = 1 if features['prevalentHyp'] == 'Oui' else 0

    return pd.DataFrame([features])

user_input = user_input_features()


if st.button('Faire la pr√©diction üß†'):
    
    model = joblib.load('best_model.pkl')
    scaler = joblib.load('scaler.pkl')

    input_data_scaled = scaler.transform(user_input)
    prediction = model.predict(input_data_scaled)
    prediction_prob = model.predict_proba(input_data_scaled)[:, 1]  # Probabilit√© de la classe positive

    if prediction[0] == 0:
        st.success("Le patient n'a pas de risque √©lev√© de maladie cardiaque. ‚úÖ")
    else:
        st.warning("Le patient pr√©sente un risque √©lev√© de maladie cardiaque. ‚ö†Ô∏è")

    st.write(f"Probabilit√© de risque √©lev√© : {prediction_prob[0]:.4f}")


